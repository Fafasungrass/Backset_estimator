import pandas as pd
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
from sklearn.model_selection import GridSearchCV





# Load your data
# Replace this with actual loading of your data
data = pd.read_csv("/D1 Infection Analysis csv.csv")

# Remove rows with NaNs
data = data.dropna()

# Convert columns with numbers represented as strings to float (if necessary)
data['Backset Added'] = data['Backset Added'].str.replace(',', '').astype(float)

# Uncomment the next line if 'Backset Added' is not already a float
# data['Backset Added'] = data['Backset Added'].str.replace(',', '').astype(float)

# Split the data into training set and test set
X = data[['Fermenter pH', 'Post-backset pH']]  # Add other columns if required
y = data['Backset Added']


# Reshape y to have two dimensions
y = y.to_numpy().reshape(-1, 1)

# Convert x from a pandas dataframe to a numpy array for optimal regression
X = X.to_numpy()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create a Linear Regression model
model = LinearRegression()

# Define the hyperparameter grid to search over
param_grid = {
    'fit_intercept': [True, False],
    'positive': [True, False],
    'copy_X': [True, False],
    'n_jobs': [-1]
}

# Define the hyperparameter tuning function
def tune_model(X_train, y_train, model):
    grid = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
    grid.fit(X_train, y_train)
    best_params = grid.best_params_
    return best_params

# Use the tune_model function to find the best hyperparameters for the model
best_params = tune_model(X_train, y_train, model)

# Train a new model with the best hyperparameters
model = LinearRegression(**best_params)

# Train the model
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Evaluate the model
print('Mean Squared Error:', mean_squared_error(y_test, y_pred))
print('R-Squared:', r2_score(y_test, y_pred))

# Ask for user input
fermenter_pH = float(input("Enter the Fermenter pH: "))

# Define the desired range of post-backset pH values
desired_post_backset_pH_range = np.arange(4.80, 5.01, 0.01).round(2)


    
# Calculate the optimal backset amount for each pH value in the range
optimal_backset_amounts = []
for pH in desired_post_backset_pH_range:
    predicted_backset = model.predict([[fermenter_pH, pH]])
    optimal_backset_amounts.append(predicted_backset[0])

mean_optimal_backset_amount = np.mean(optimal_backset_amounts)
optimal_pH_index = np.abs(optimal_backset_amounts - mean_optimal_backset_amount).argmin()
optimal_pH = desired_post_backset_pH_range[optimal_pH_index]


desired_post_backset_pH_index = np.where((desired_post_backset_pH_range >= 4.80) & (desired_post_backset_pH_range <= 5.00))[0][0]

print(f"Given a fermenter pH of {fermenter_pH}, add {int(np.round(optimal_backset_amounts[optimal_pH_index]))} gallons of backset for a desired post-backset pH of {optimal_pH:.2f}")



plt.figure(figsize=(10, 6))
plt.scatter(X_test[:, 0], y_test, s=50, c='blue', alpha=0.3, label='Actual Backset Added')
plt.scatter(X_test[:, 0], y_pred, s=50, c='red', alpha=0.3, label='Predicted Backset to Add')
plt.xlabel('Fermenter pH')
plt.ylabel('Backset Added')

plt.legend()
plt.show()
